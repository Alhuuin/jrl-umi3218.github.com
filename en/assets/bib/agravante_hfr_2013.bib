@InProceedings{agravante:hfr:2013,
  author    = {Agravante,Don Joven and Cherubini,Andrea and Kheddar,Abderrahmane},
  title     = {Visio-haptic control for Human-Humanoid Cooperative Carrying},
  booktitle = {International Workshop on Human-Friendly Robotics},
  year      = {2013},
  address   = {Roma, Italy},
  month     = {September\textasciitilde 25--26},
  url       = {https://hfr13.files.wordpress.com/2013/08/08agravante.pdf},
  doi       = {lirmm-01247143},
  abstract  = {Humanoid robotics focuses on the design of robots directly inspired by human capabilities. This design gives many advantages when working together with humans. Because of this, humanoids are ideal research platforms for physical Human-Robot Interaction (pHRI). The particular focus of this work is in the integration of visual servoing in pHRI, specifically in human-humanoid collaborative tasks. Early work on human-humanoid collaboration was done in [3], where a panel is transported, and vision it used to recognize it. However, this involves an interaction of the robot with the panel only, and not with the human. In this work, a first step is taken towards using vision in human-humanoid haptic joint actions. Haptic interaction exists when forces applied by the human on the carried object are felt by the robot and vice-versa. In this research area, the focus is on regulating the interaction forces for safety, and on making the robot proactive in helping the human [4], [5]. Since physical interaction is fundamental, most works use data from force/torque sensors only. However, force/torque data is not rich enough for some tasks, where vision can provide new information. The focus of the work here is a carrying task where human and robot grasp an object at opposite ends and move it together. This task has been studied in [6], where the height at which the robot holds the table is kept constant, with no regard for how the human holds the table at the other end. However, it is desirable to keep the table horizontal to avoid objects on top from sliding. Besides, the robot should adjust to the human when s/he is leading the task. The strategy taken here is using vision to observe the table inclination and then servoing the height to correct it. This is done while regulating the interaction forces. The six degrees of freedom (DOF) of the table, X = [X, Y, Z, \varphi  x , \varphi  y , \varphi  z ] \in  SE (3) can be controlled using the humanoid right and left hands. Figure 1 shows the control framework, with its two main modules: the Stack-of-Tasks, a generalized inverse kinematics abstraction layer [7], and an impedance controller. Impedance control is a method for regulating the contact of a robot with its environment [8]. Here, it is applied to track a desired trajectory (X d , \textperiodcentered  X d , \textasciidieresis  X d), given the force and torque measured at the robot wrists. In [6], only the projection of the table on the ground (X, Y, \varphi  z) was controlled, as for an object moving on a plane. Here, Z is also regulated. Since controlling the 2 remaining DOFs does not fit with the task of keeping the table horizontal, these are left compliant (\varphi  x = \varphi  y = 0).}
}