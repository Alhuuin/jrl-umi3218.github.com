@InProceedings{kita:humanoids:2013b,
  author    = {Kita, Yasuyo and Ueshiba, Toshio and Kanehiro, Fumio and Kita, Nobuyuki},
  title     = {Recognizing clothing states using 3D data observed from multiple directions},
  booktitle = {IEEE-RAS International Conference on Humanoid Robots},
  year      = {2013},
  address   = {Atlanta, Geogia, USA},
  month     = {October 15-October 17},
  url       = {https://www.researchgate.net/profile/Nobuyuki-Kita/publication/282255047\_Recognizing\_clothing\_states\_using\_3D\_data\_observed\_from\_multiple\_directions/links/56a1b62a08ae24f6270212f5/Recognizing-clothing-states-using-3D-data-observed-from-multiple-directions.pdf},
  keywords  = {Three-dimensional displays, Shape, Clothing, Data models, Solid modeling, Deformable models, Cameras},
  doi       = {10.1109/HUMANOIDS.2013.7029980},
  abstract  = {In this paper, we propose a method of recognizing the state of a clothing item by using three-dimensional(3D) data observed from multiple directions in an integrated manner. The situation dealt with in this paper is that a clothing item is observed from different directions by rotating it along a vertical axis. First, sets of 3D points obtained from each observation are integrated on a depth buffer image which lies on the side of a cylinder containing the item (CZ buffer image). Then, CZ buffer is expanded into a new depth buffer image, whose horizontal axis is akin to geodesic distance on the clothing surface (EZ buffer image). As a result, the region where 3D points are stored in EZ buffer images approximates \textquotedblleft a view of flattened surface\textquotedblright  of the item, which is stable regardless of the variation in 3D shape of the item as far as the item is held at the same position. Experimental results using both synthetic images and actually observed images demonstrated that the similarity of regions in EZ buffer images is an effective measure for recognizing clothing states.}
}