@InProceedings{tanguy:simpar:2018,
  author    = {Tanguy, Arnaud and Kheddar, Abderrahmane and Comport, Andrew},
  title     = {Online eye-robot self-calibration},
  booktitle = {IEEE International Conference on Simulation, Modeling, and Programming for Autonomous Robots},
  year      = {2018},
  pages     = {68--73},
  address   = {Brisbane, Australia},
  month     = {May 16-May 19},
  doi       = {10.1109/SIMPAR.2018.8376273},
  abstract  = {We present a new approach that extends the well known Eye-Hand calibration to the online whole-body calibration of the kinematic tree geometric parameters. Only on-board RGB-D sensor and joint encoders are required. Online calibration allows to estimate the state of the kinematic tree at any time, and thus account for inaccurate models, passive joints, mechanical wear, unexpected damages, etc. One major challenge in achieving such an online self-calibration procedure with the available sensors is that the observability of the calibrated parameters cannot always be guaranteed. In this work, we determine the effect of joint degrees of freedom on observability. From this, we propose a novel Eye-Robot calibration method that determines the geometric transformations between joints. Conditions on joint motion are further used to improve upon existing kinematic tree parameters when observability is incomplete. In practice a dense SLAM algorithm is used for online pose estimation and the results are demonstrated with an HRP-4 humanoid robot.}
}